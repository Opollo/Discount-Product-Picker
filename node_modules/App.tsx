import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Part } from '@google/genai';
import Header from './components/Header';
import ChatWindow from './components/ChatWindow';
import InputBar from './components/InputBar';
import { WhatsAppIcon } from './components/icons';
import { Message, ConversationStage } from './types';
import { getAiResponse, transcribeAudio } from './services/geminiService';
import { fileToBase64 } from './utils/fileUtils';
import { DISTRICT_WHATSAPP_NUMBER, EVIDENCE_PROMPTS } from './constants';

const App: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [conversationStage, setConversationStage] = useState<ConversationStage>(ConversationStage.AWAITING_TITLE);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  
  const [isTtsEnabled, setIsTtsEnabled] = useState<boolean>(false);
  
  const [attachedFile, setAttachedFile] = useState<File | null>(null);
  const [fileError, setFileError] = useState<string | null>(null);

  const [isRecording, setIsRecording] = useState<boolean>(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const [evidenceContext, setEvidenceContext] = useState<string | null>(null);
  const [showWhatsAppButton, setShowWhatsAppButton] = useState<boolean>(false);
  const [finalSummary, setFinalSummary] = useState<string>('');
  
  const initialMessage: Message = {
    id: Date.now().toString(),
    sender: 'ai',
    text: "Welcome to the Kole District Grievance Guidance System. I am Kole Guide, your AI assistant. To help you effectively, please tell me your official title or position.",
  };

  useEffect(() => {
    setMessages([initialMessage]);
  }, []);

  const toggleTts = () => {
    if (isTtsEnabled) {
      window.speechSynthesis.cancel();
    }
    setIsTtsEnabled(prev => !prev);
  };
  
  const speak = useCallback((text: string) => {
    if (!isTtsEnabled) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    window.speechSynthesis.speak(utterance);
  }, [isTtsEnabled]);

  const handleClearChat = useCallback(() => {
    window.speechSynthesis.cancel();

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      mediaRecorderRef.current = null;
    }
    audioChunksRef.current = [];
    setIsRecording(false);
    
    setMessages([initialMessage]);
    setConversationStage(ConversationStage.AWAITING_TITLE);
    setIsLoading(false);
    setAttachedFile(null);
    setFileError(null);
    setEvidenceContext(null);
    setShowWhatsAppButton(false);
    setFinalSummary('');
  }, [initialMessage]);

  const handleSendMessage = useCallback(async (text: string, file?: File) => {
    if (isLoading) return;

    const userMessage: Message = { id: Date.now().toString(), text, sender: 'user' };
    if (file) {
      userMessage.file = { name: file.name, type: file.type };
    }
    
    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);
    setFileError(null);
    setEvidenceContext(null);
    setShowWhatsAppButton(false);

    let fileParts: Part[] = [];
    if (file) {
      try {
        const base64Data = await fileToBase64(file);
        fileParts.push({ inlineData: { data: base64Data, mimeType: file.type } });
      } catch (error) {
        console.error("Error converting file to base64:", error);
        setFileError("Could not process the attached file.");
        setIsLoading(false);
        return;
      }
    }

    try {
      const history = messages;
      const aiResponseText = await getAiResponse(history, conversationStage, text, fileParts);
      
      let cleanText = aiResponseText;
      const evidencePromptRegex = /\[EVIDENCE_PROMPT:(.+?)\]/;
      const evidenceMatch = aiResponseText.match(evidencePromptRegex);
      if (evidenceMatch) {
          const category = evidenceMatch[1];
          setEvidenceContext(category);
          cleanText = aiResponseText.replace(evidencePromptRegex, '').trim();
      }

      if (aiResponseText.includes('[ACTION:FINALIZE_GRIEVANCE]')) {
          setShowWhatsAppButton(true);
          const summaryMsg = [...messages, userMessage].reverse().find(m => m.sender === 'ai' && m.text.startsWith('**Grievance Summary**'));
          if(summaryMsg) {
            setFinalSummary(summaryMsg.text);
          }
          cleanText = aiResponseText.replace('[ACTION:FINALIZE_GRIEVANCE]', '').trim();
      }

      const aiMessage: Message = { id: (Date.now() + 1).toString(), text: cleanText, sender: 'ai' };
      setMessages(prev => [...prev, aiMessage]);
      speak(cleanText);

      // Advance conversation stage
      if (conversationStage === ConversationStage.AWAITING_TITLE) {
          setConversationStage(ConversationStage.AWAITING_GRIEVANCE_DESCRIPTION);
      } else if (conversationStage === ConversationStage.AWAITING_GRIEVANCE_DESCRIPTION) {
          setConversationStage(ConversationStage.AWAITING_CATEGORY_CONFIRMATION);
      } else if (conversationStage === ConversationStage.AWAITING_CATEGORY_CONFIRMATION) {
          setConversationStage(ConversationStage.AWAITING_EVIDENCE);
      } else if (conversationStage === ConversationStage.AWAITING_EVIDENCE) {
          setConversationStage(ConversationStage.AWAITING_SUMMARY_CONFIRMATION);
      } else if (conversationStage === ConversationStage.AWAITING_SUMMARY_CONFIRMATION) {
          if (text.toLowerCase().startsWith('yes') || text.toLowerCase().startsWith('correct')) {
            setConversationStage(ConversationStage.FINALIZED);
          }
      }
    } catch (error) {
      console.error("Error getting AI response:", error);
      const errorMessage: Message = { id: (Date.now() + 1).toString(), text: "Sorry, I encountered an error. Please try again.", sender: 'ai' };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
      setAttachedFile(null);
    }
  }, [isLoading, messages, conversationStage, speak]);

  const handleFeedback = useCallback((messageId: string, feedback: 'up' | 'down') => {
    setMessages(prevMessages =>
      prevMessages.map(msg => {
        if (msg.id === messageId) {
          if (msg.feedback === feedback) {
            return { ...msg, feedback: undefined, feedbackText: undefined };
          }
          return { ...msg, feedback };
        }
        return msg;
      })
    );
  }, []);

  const handleFeedbackText = useCallback((messageId: string, text: string) => {
    setMessages(prevMessages =>
      prevMessages.map(msg => {
        if (msg.id === messageId) {
          return { ...msg, feedbackText: text };
        }
        return msg;
      })
    );
  }, []);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorderRef.current = new MediaRecorder(stream);
      audioChunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = event => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorderRef.current.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        try {
            const tempMessage: Message = { id: Date.now().toString(), text: 'Processing your audio...', sender: 'user' };
            setMessages(prev => [...prev, tempMessage]);
            setIsLoading(true);

            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = async () => {
                const base64Audio = (reader.result as string).split(',')[1];
                try {
                    const transcribedText = await transcribeAudio(base64Audio, 'audio/webm');
                    setMessages(prev => prev.filter(m => m.id !== tempMessage.id)); // remove processing message
                    if (transcribedText) {
                        handleSendMessage(transcribedText);
                    } else {
                         const errorMessage: Message = { id: (Date.now() + 1).toString(), text: "Could not understand audio. Please try again.", sender: 'ai' };
                         setMessages(prev => [...prev, errorMessage]);
                         setIsLoading(false);
                    }
                } catch(e) {
                    console.error("Transcription error", e);
                    setMessages(prev => prev.filter(m => m.id !== tempMessage.id));
                    const errorMessage: Message = { id: (Date.now() + 1).toString(), text: "Sorry, there was an error transcribing your audio.", sender: 'ai' };
                    setMessages(prev => [...prev, errorMessage]);
                    setIsLoading(false);
                }
            };
        } catch (e) {
             console.error("Error processing audio blob", e)
             setIsLoading(false);
        }
      };

      mediaRecorderRef.current.start();
      setIsRecording(true);
    } catch (err) {
      console.error("Error accessing microphone:", err);
      setFileError("Microphone access was denied. Please enable it in your browser settings.");
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
    }
  };
  
  const shareOnWhatsApp = () => {
      const text = finalSummary.replace(/\*\*/g, '*'); // Convert markdown bold to WhatsApp bold
      const url = `https://wa.me/${DISTRICT_WHATSAPP_NUMBER}?text=${encodeURIComponent(text)}`;
      window.open(url, '_blank');
  };

  return (
    <div className="h-screen w-screen flex flex-col font-sans bg-gray-100">
      <Header isTtsEnabled={isTtsEnabled} onToggleTts={toggleTts} onClearChat={handleClearChat} />
      <main className="flex-1 flex flex-col mt-[80px]">
        <ChatWindow messages={messages} isLoading={isLoading} onFeedback={handleFeedback} onFeedbackText={handleFeedbackText} />

        <div className="p-3 sm:p-4 border-t border-gray-200 bg-white">
            {fileError && <div className="text-red-600 text-sm mb-2 text-center">{fileError}</div>}
            {evidenceContext && EVIDENCE_PROMPTS[evidenceContext] && <div className="text-blue-700 bg-blue-100 p-3 rounded-lg text-sm mb-3">{EVIDENCE_PROMPTS[evidenceContext]}</div>}

            {showWhatsAppButton && (
                <button 
                  onClick={shareOnWhatsApp}
                  className="w-full flex items-center justify-center gap-2 mb-3 px-4 py-3 bg-green-500 text-white font-bold rounded-lg hover:bg-green-600 transition-colors"
                >
                    <WhatsAppIcon className="h-6 w-6"/>
                    Share Summary on WhatsApp
                </button>
            )}

            <InputBar 
                onSendMessage={handleSendMessage}
                onStartRecording={startRecording}
                onStopRecording={stopRecording}
                isRecording={isRecording}
                isLoading={isLoading}
                attachedFile={attachedFile}
                setAttachedFile={setAttachedFile}
                setFileError={setFileError}
            />
        </div>
      </main>
    </div>
  );
};

export default App;
